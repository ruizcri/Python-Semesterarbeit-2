{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a566dcbc-18f7-4de4-b199-fb2cdbf84ca3",
   "metadata": {},
   "source": [
    "# Python Semesterarbeit 2\n",
    "\n",
    "### 1. Funktion tf_read \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae71a2a6-9fb9-478c-98c9-cc388253999a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wortfrequenzen in der Datei:\n",
      "Kapitel: 2\n",
      "1: 3\n",
      "Einführung: 9\n",
      "in: 27\n",
      "Daten: 15\n",
      "Variable/Merkmal: 1\n",
      "und: 32\n",
      "Observation: 3\n",
      "Eine: 6\n",
      "Variable: 9\n",
      "ist: 19\n",
      "ein: 5\n",
      "messbares: 1\n",
      "Merkmal: 2\n",
      "oder: 16\n",
      "eine: 25\n",
      "Eigenschaft: 1\n",
      "das/die: 1\n",
      "einer: 8\n",
      "Studie: 1\n",
      "gemessen: 4\n",
      "beobachtet: 2\n",
      "wird: 7\n",
      "Zum: 1\n",
      "Beispiel: 9\n",
      "könnten: 3\n",
      "Kundenumfrage: 1\n",
      "die: 82\n",
      "Variablen: 16\n",
      "Kaufverhalten: 1\n",
      "Alter: 3\n",
      "Einkommen: 2\n",
      "Zufriedenheit: 1\n",
      "sein: 2\n",
      "Jeder: 1\n",
      "Kunde: 1\n",
      "der: 35\n",
      "an: 8\n",
      "Umfrage: 3\n",
      "teilnimmt: 2\n",
      "stellt: 2\n",
      "dar: 2\n",
      "Fallbeispiel: 8\n",
      "Nehmen: 2\n",
      "wir: 2\n",
      "du: 13\n",
      "führst: 1\n",
      "zur: 2\n",
      "Bewertung: 2\n",
      "von: 19\n",
      "Filmen: 1\n",
      "durch: 6\n",
      "Hierbei: 1\n",
      "sind: 11\n",
      "Merkmale: 2\n",
      "den: 17\n",
      "Teilnehmern: 1\n",
      "erfassen: 1\n",
      "möchtest: 8\n",
      "wie: 6\n",
      "Filmtitel: 1\n",
      "Jede: 1\n",
      "Person: 2\n",
      "Diese: 3\n",
      "Personen: 1\n",
      "Grundgesamtheit: 6\n",
      "über: 3\n",
      "Informationen: 3\n",
      "sammeln: 2\n",
      "Kategoriale: 2\n",
      "metrische: 3\n",
      "unterteilen: 1\n",
      "Einheiten: 1\n",
      "verschiedene: 2\n",
      "Kategorien: 7\n",
      "Gruppen: 4\n",
      "Sie: 2\n",
      "beschreiben: 2\n",
      "Eigenschaften: 1\n",
      "nicht: 7\n",
      "quantifizierbar: 2\n",
      "Geschlecht: 1\n",
      "Farben: 3\n",
      "Bildungsstufen: 1\n",
      "Im: 1\n",
      "Gegensatz: 1\n",
      "dazu: 1\n",
      "haben: 5\n",
      "messbare: 1\n",
      "Werte: 3\n",
      "sei: 1\n",
      "es: 8\n",
      "diskret: 1\n",
      "ganze: 1\n",
      "Zahlen: 1\n",
      "stetig: 1\n",
      "beliebige: 1\n",
      "Temperatur: 1\n",
      "2: 3\n",
      "sammelst: 1\n",
      "Autos: 2\n",
      "darunter: 2\n",
      "Farbe: 1\n",
      "z: 1\n",
      "B: 1\n",
      "rot: 1\n",
      "blau: 1\n",
      "grün: 1\n",
      "als: 4\n",
      "kategoriale: 1\n",
      "Geschwindigkeit: 1\n",
      "während: 2\n",
      "Geschwindigkeiten: 1\n",
      "numerische: 1\n",
      "werden: 14\n",
      "können: 2\n",
      "Nominale: 2\n",
      "keine: 3\n",
      "natürliche: 1\n",
      "Reihenfolge: 3\n",
      "Rangordnung: 1\n",
      "Das: 1\n",
      "bedeutet: 1\n",
      "dass: 3\n",
      "sie: 3\n",
      "sich: 3\n",
      "keiner: 1\n",
      "bestimmten: 1\n",
      "Weise: 1\n",
      "hierarchisch: 1\n",
      "anordnen: 1\n",
      "lassen: 1\n",
      "Ein: 14\n",
      "für: 8\n",
      "nominale: 1\n",
      "Geschlechter: 1\n",
      "männlich: 1\n",
      "weiblich: 1\n",
      "divers: 1\n",
      "Ländernamen: 1\n",
      "Augenfarben: 1\n",
      "sinnvoll: 1\n",
      "gebracht: 1\n",
      "da: 3\n",
      "Wertung: 1\n",
      "Rangfolge: 3\n",
      "impliziert: 1\n",
      "Ordinale: 2\n",
      "hingegen: 3\n",
      "bestimmte: 3\n",
      "zwischen: 7\n",
      "aber: 2\n",
      "Abstand: 1\n",
      "notwendigerweise: 1\n",
      "gleichmäßig: 2\n",
      "ordinale: 1\n",
      "Bildungsniveau: 2\n",
      "z.B: 1\n",
      "Grundschule: 1\n",
      "Mittelschule: 1\n",
      "Hochschule: 1\n",
      "hier: 1\n",
      "gewisse: 1\n",
      "besteht: 1\n",
      "tatsächliche: 1\n",
      "Unterschied: 1\n",
      "im: 5\n",
      "kann: 2\n",
      "Abhängige: 1\n",
      "unabhängige: 3\n",
      "Die: 12\n",
      "abhängige: 3\n",
      "das: 9\n",
      "untersuchst: 1\n",
      "messt: 1\n",
      "um: 14\n",
      "festzustellen: 2\n",
      "ob: 5\n",
      "Veränderungen: 2\n",
      "anderen: 1\n",
      "beeinflusst: 3\n",
      "potenzielle: 2\n",
      "Einflussgröße: 1\n",
      "vermutet: 1\n",
      "3: 2\n",
      "Angenommen: 3\n",
      "Einfluss: 6\n",
      "Übung: 3\n",
      "auf: 15\n",
      "Herzfrequenz: 3\n",
      "untersuchen: 6\n",
      "Menge: 2\n",
      "körperlicher: 2\n",
      "abhängig: 1\n",
      "möglicherweise: 1\n",
      "Beobachtungsstudie: 3\n",
      "Experiment: 3\n",
      "Ereignisse: 1\n",
      "ohne: 1\n",
      "aktiv: 1\n",
      "Ablauf: 1\n",
      "einzugreifen: 1\n",
      "zielt: 1\n",
      "darauf: 1\n",
      "ab: 1\n",
      "bestehende: 1\n",
      "Zusammenhänge: 1\n",
      "zu: 22\n",
      "identifizieren: 1\n",
      "geplantes: 1\n",
      "Vorgehen: 1\n",
      "bei: 3\n",
      "dem: 5\n",
      "Forscher: 5\n",
      "bewusst: 1\n",
      "gesteuerte: 1\n",
      "vornimmt: 1\n",
      "Auswirkungen: 1\n",
      "mehrere: 1\n",
      "analysieren: 4\n",
      "4: 2\n",
      "Du: 5\n",
      "Sonnenlicht: 3\n",
      "Pflanzenwachstum: 1\n",
      "würde: 5\n",
      "darin: 1\n",
      "bestehen: 1\n",
      "Pflanzen: 2\n",
      "unterschiedlichem: 1\n",
      "beobachten: 1\n",
      "einen: 5\n",
      "Zusammenhang: 2\n",
      "Lichtintensität: 1\n",
      "Wachstum: 2\n",
      "gibt: 6\n",
      "bedeuten: 1\n",
      "einige: 2\n",
      "gezielt: 1\n",
      "auszusetzen: 1\n",
      "andere: 2\n",
      "Schatten: 1\n",
      "halten: 1\n",
      "des: 3\n",
      "Lichts: 1\n",
      "Stichprobe: 6\n",
      "Gesamtheit: 3\n",
      "Elemente: 2\n",
      "gesammelt: 1\n",
      "sollen: 1\n",
      "Da: 3\n",
      "oft: 2\n",
      "praktikabel: 1\n",
      "alle: 1\n",
      "wählen: 1\n",
      "aus: 4\n",
      "Rückschlüsse: 2\n",
      "ziehen: 4\n",
      "5: 3\n",
      "Stell: 1\n",
      "dir: 1\n",
      "vor: 1\n",
      "Durchschnittseinkommen: 1\n",
      "aller: 2\n",
      "Angestellten: 2\n",
      "einem: 1\n",
      "Unternehmen: 3\n",
      "ermitteln: 2\n",
      "wäre: 1\n",
      "Mitarbeiter: 3\n",
      "jedoch: 1\n",
      "zeitaufwändig: 1\n",
      "teuer: 1\n",
      "könnte: 5\n",
      "allen: 1\n",
      "Mitarbeitern: 2\n",
      "würdest: 1\n",
      "stattdessen: 1\n",
      "beispielsweise: 1\n",
      "100: 2\n",
      "auswählen: 1\n",
      "Grundlage: 1\n",
      "dieser: 1\n",
      "gesamte: 2\n",
      "Belegschaft: 1\n",
      "Stichprobenauswahl: 1\n",
      "Es: 1\n",
      "Methoden: 3\n",
      "einfache: 2\n",
      "Zufallsstichproben: 1\n",
      "stratifizierte: 2\n",
      "Stichproben: 1\n",
      "Cluster-Stichproben: 1\n",
      "Mehrstufen-Stichproben: 1\n",
      "6: 2\n",
      "Musikpräferenzen: 1\n",
      "Schülern: 3\n",
      "Schule: 2\n",
      "Anstatt: 1\n",
      "Schülerpopulation: 1\n",
      "befragen: 1\n",
      "könntest: 3\n",
      "Zufallsstichprobe: 1\n",
      "200: 1\n",
      "Vielfalt: 1\n",
      "Präferenzen: 1\n",
      "auch: 1\n",
      "verwenden: 2\n",
      "indem: 3\n",
      "Schüler: 4\n",
      "nach: 1\n",
      "Klassenstufen: 1\n",
      "aufteilst: 1\n",
      "jeder: 2\n",
      "Stufe: 1\n",
      "Anzahl: 4\n",
      "auswählst: 1\n",
      "Grundprinzipien: 2\n",
      "statistischer: 1\n",
      "Experimente: 2\n",
      "gute: 1\n",
      "statistische: 1\n",
      "Kontrolle: 2\n",
      "Randomisierung: 2\n",
      "Reproduzierbarkeit: 1\n",
      "Vergleich: 1\n",
      "7: 1\n",
      "Wirksamkeit: 2\n",
      "eines: 2\n",
      "neuen: 2\n",
      "Medikaments: 1\n",
      "Schmerzlinderung: 1\n",
      "wählst: 1\n",
      "zwei: 1\n",
      "Patienten: 1\n",
      "erhält: 3\n",
      "Medikament: 1\n",
      "Placebo: 1\n",
      "Beide: 1\n",
      "ähnliche: 1\n",
      "gewährleisten: 1\n",
      "verabreichst: 1\n",
      "Substanzen: 1\n",
      "zufällig: 1\n",
      "vergleichst: 1\n",
      "dann: 1\n",
      "Schmerzreduktion: 1\n",
      "beurteilen: 1\n",
      "Durch: 1\n",
      "sichergestellt: 1\n",
      "Ergebnisse: 3\n",
      "unkontrollierte: 1\n",
      "verzerrt: 1\n",
      "Reduzierung: 1\n",
      "menschlichen: 3\n",
      "Einflusses: 1\n",
      "Um: 2\n",
      "minimieren: 2\n",
      "Doppelblindstudien: 1\n",
      "durchgeführt: 1\n",
      "denen: 1\n",
      "weder: 2\n",
      "Teilnehmer: 2\n",
      "noch: 2\n",
      "wissen: 2\n",
      "welcher: 1\n",
      "Gruppe: 6\n",
      "zugewiesen: 1\n",
      "wurde: 1\n",
      "Dadurch: 1\n",
      "Vorurteile: 2\n",
      "Erwartungshaltungen: 2\n",
      "reduziert: 1\n",
      "beeinflussen: 2\n",
      "8: 1\n",
      "Trainingsprogramms: 1\n",
      "Ausdauer: 1\n",
      "testen: 1\n",
      "Doppelblindstudie: 1\n",
      "durchführen: 1\n",
      "welche: 2\n",
      "intensive: 1\n",
      "Training: 2\n",
      "herkömmliche: 1\n",
      "Änderung: 1\n",
      "Dies: 3\n",
      "hilft: 1\n",
      "reduzieren: 1\n",
      "Summarizing: 1\n",
      "Data: 2\n",
      "2.1: 1\n",
      "Examining: 1\n",
      "numerical: 1\n",
      "Scatterplots: 1\n",
      "gepaarte: 1\n",
      "Erklärung: 6\n",
      "Scatterplot: 2\n",
      "Grafik: 1\n",
      "Punkte: 2\n",
      "Koordinatensystem: 1\n",
      "darstellt: 2\n",
      "wobei: 4\n",
      "jede: 1\n",
      "Achse: 3\n",
      "repräsentiert: 3\n",
      "Wenn: 1\n",
      "gepaart: 1\n",
      "entsprechend: 1\n",
      "jeweiligen: 1\n",
      "Paaren: 1\n",
      "Datenpunkten: 1\n",
      "platziert: 3\n",
      "Beziehung: 1\n",
      "beiden: 1\n",
      "visualisieren: 1\n",
      "Firma: 1\n",
      "möchte: 3\n",
      "verbrachten: 1\n",
      "Stunden: 2\n",
      "Vorbereitung: 2\n",
      "Prüfung: 1\n",
      "tatsächlich: 1\n",
      "erzielten: 1\n",
      "Note: 3\n",
      "erstellt: 3\n",
      "jeden: 2\n",
      "Punkt: 4\n",
      "x-Achse: 1\n",
      "y-Achse: 1\n",
      "erzielte: 1\n",
      "darstellen: 1\n",
      "ermöglicht: 1\n",
      "sehen: 1\n",
      "höhere: 2\n",
      "Vorbereitungsstunden: 1\n",
      "mit: 1\n",
      "besseren: 1\n",
      "Noten: 5\n",
      "korrelieren: 1\n",
      "Dot: 4\n",
      "Plots: 1\n",
      "Durchschnitt: 6\n",
      "Plot: 3\n",
      "Art: 1\n",
      "Diagramm: 1\n",
      "Datenpunkt: 1\n",
      "horizontalen: 1\n",
      "dargestellt: 2\n",
      "Der: 2\n",
      "Mittelwert: 1\n",
      "Summe: 1\n",
      "Datenpunkte: 6\n",
      "geteilt: 1\n",
      "In: 1\n",
      "Klasse: 1\n",
      "Mathetest: 1\n",
      "gemacht: 2\n",
      "seine: 1\n",
      "durchschnittlichen: 3\n",
      "Testwert: 1\n",
      "visuell: 1\n",
      "zeigen: 3\n",
      "Histogramme: 1\n",
      "Form: 1\n",
      "Histogramm: 2\n",
      "grafische: 2\n",
      "Darstellung: 2\n",
      "Verteilung: 3\n",
      "X-Achse: 2\n",
      "Intervalle: 1\n",
      "unterteilt: 1\n",
      "Y-Achse: 1\n",
      "Häufigkeit: 1\n",
      "jedem: 2\n",
      "Intervall: 1\n",
      "Altersverteilung: 1\n",
      "seiner: 1\n",
      "Altersgruppen: 1\n",
      "Intervallen: 1\n",
      "abgebildet: 1\n",
      "Höhe: 1\n",
      "Balken: 1\n",
      "Altersintervall: 1\n",
      "zeigt: 1\n",
      "Varianz: 4\n",
      "Standardabweichung: 3\n",
      "misst: 1\n",
      "durchschnittliche: 3\n",
      "Abweichung: 2\n",
      "vom: 1\n",
      "Quadratwurzel: 1\n",
      "stark: 2\n",
      "streuen: 1\n",
      "hat: 1\n",
      "Mathematiktests: 1\n",
      "ihre: 1\n",
      "wurden: 1\n",
      "Skala: 1\n",
      "0: 1\n",
      "bis: 1\n",
      "anzeigen: 2\n",
      "weit: 1\n",
      "Testnote: 1\n",
      "abweichen: 2\n",
      "derselben: 1\n",
      "Einheit: 1\n",
      "ursprünglichen: 1\n",
      "messen: 1\n",
      "Boxplots: 1\n",
      "Quartile: 3\n",
      "Median: 4\n",
      "Boxplot: 2\n",
      "25: 1\n",
      "Perzentil: 2\n",
      "75: 1\n",
      "mögliche: 1\n",
      "Ausreißer: 5\n",
      "anzeigt: 1\n",
      "Box: 1\n",
      "Bereich: 1\n",
      "meisten: 1\n",
      "liegen: 1\n",
      "Whisker\"-Linien: 1\n",
      "Streuung: 1\n",
      "Testergebnisse: 1\n",
      "Mathematiktest: 1\n",
      "unteres: 1\n",
      "Quartil: 2\n",
      "oberes: 1\n",
      "allgemeinen: 1\n",
      "Robuste: 2\n",
      "Statistik: 2\n",
      "bezieht: 1\n",
      "weniger: 1\n",
      "empfindlich: 1\n",
      "gegenüber: 1\n",
      "Ausreißern: 1\n",
      "abweichenden: 1\n",
      "Werten: 1\n",
      "bieten: 1\n",
      "stabilere: 2\n",
      "Analysen: 1\n",
      "insbesondere: 1\n",
      "wenn: 1\n",
      "perfekt: 1\n",
      "normal: 1\n",
      "verteilt: 1\n",
      "enthalten: 1\n",
      "untersucht: 1\n",
      "Gehalt: 1\n",
      "leitende: 1\n",
      "Angestellte: 1\n",
      "viel: 1\n",
      "Gehälter: 1\n",
      "Rest: 1\n",
      "verdienen: 1\n",
      "entscheidet: 1\n",
      "er: 1\n",
      "dafür: 1\n",
      "anstelle: 1\n",
      "Durchschnitts: 1\n",
      "Schätzung: 1\n",
      "Gehalts: 1\n",
      "erhalten: 1\n",
      "minimiert: 1\n",
      "Verzerrung: 1\n",
      "a: 1\n",
      "About: 1\n",
      "30: 1\n",
      "b: 1\n",
      "Since: 1\n",
      "the: 7\n",
      "distribution: 1\n",
      "is: 4\n",
      "right: 1\n",
      "skewed: 1\n",
      "mean: 1\n",
      "higher: 2\n",
      "than: 4\n",
      "median: 1\n",
      "c: 1\n",
      "Q1: 2\n",
      "between: 2\n",
      "15: 1\n",
      "and: 3\n",
      "20: 4\n",
      "Q3: 2\n",
      "35: 1\n",
      "40: 1\n",
      "IQR: 4\n",
      "about: 1\n",
      "d: 1\n",
      "Values: 1\n",
      "that: 1\n",
      "are: 2\n",
      "considered: 2\n",
      "to: 2\n",
      "be: 2\n",
      "unusually: 2\n",
      "low: 2\n",
      "or: 2\n",
      "high: 2\n",
      "lie: 1\n",
      "more: 1\n",
      "1.5: 3\n",
      "away: 1\n",
      "from: 1\n",
      "quartiles: 1\n",
      "Upper: 1\n",
      "fence: 2\n",
      "37:5: 1\n",
      "1:5: 1\n",
      "67:5: 1\n",
      "Lower: 1\n",
      "17:5􀀀1:5: 1\n",
      "􀀀12:5: 1\n",
      "The: 1\n",
      "lowest: 1\n",
      "AQI: 3\n",
      "recorded: 2\n",
      "not: 2\n",
      "lower: 1\n",
      "highest: 1\n",
      "65: 1\n",
      "which: 1\n",
      "both: 1\n",
      "within: 1\n",
      "fences: 1\n",
      "Therefore: 1\n",
      "none: 1\n",
      "of: 1\n",
      "days: 1\n",
      "this: 1\n",
      "sample: 1\n",
      "would: 1\n",
      "have: 1\n",
      "Für: 1\n",
      "Artbei: 1\n",
      "RMarkdown: 1\n",
      "gebraucht: 1\n"
     ]
    }
   ],
   "source": [
    "# Importieren des Moduls \"docx\" für Textverarbeitung von Word Dokumenten\n",
    "import docx\n",
    "\n",
    "# Import des Moduls \"string\" \n",
    "import string\n",
    "\n",
    "def tf_read(dateipfad):\n",
    "    # Initialisieren des leeren Wörterbuches für die Wortfrequenz\n",
    "    wort_frequenz = {}\n",
    "\n",
    "    try:\n",
    "        # Öffnen der .docx-Datei\n",
    "        doc = docx.Document(dateipfad)\n",
    "\n",
    "        # Verwandlung in einen einzelnen Textblock, damit weiterverabeitet werden kann.\n",
    "        text = ' '.join(paragraph.text for paragraph in doc.paragraphs)\n",
    "        \n",
    "         # Text aus dem Dokument extrahieren und in Wörter aufteilen\n",
    "        woerter = text.split()\n",
    "\n",
    "        # Entfernen von Satzzeichen und Zählen der Wörter\n",
    "        for wort in woerter:\n",
    "            wort = wort.strip(string.punctuation)\n",
    "            if len(wort) > 0:\n",
    "                if wort in wort_frequenz:\n",
    "                    wort_frequenz[wort] += 1\n",
    "                else:\n",
    "                    wort_frequenz[wort] = 1\n",
    "\n",
    "        return wort_frequenz\n",
    "    \n",
    "    # Code für den Fall dass Datei nicht gefunden wird\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Datei {dateipfad} wurde nicht gefunden.\")\n",
    "        return None\n",
    "\n",
    "# Beispielaufruf:\n",
    "dateipfad = '/Users/cristianruiz/Desktop/CAS/Python/Semesterarbeit 2/Dokumente/Kapitel 1.docx'\n",
    "\n",
    "# Funktion aufrufen und Wortfrequenzen erhalten\n",
    "wort_frequenz = tf_read(dateipfad)\n",
    "\n",
    "if wort_frequenz:\n",
    "    print(\"Wortfrequenzen in der Datei:\")\n",
    "    for wort, haeufigkeit in wort_frequenz.items():\n",
    "        print(f\"{wort}: {haeufigkeit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba34d22-0490-4ee7-a869-c0139231d634",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Erklärung zum Code:**\n",
    "\n",
    "Dieser Code wurde erstellt, um `.docx`-Dokumente zu lesen und die Wortfrequenz aus einem gegebenen Dateipfad zu extrahieren. Um dies zu ermöglichen, wird das \"docx\"-Modul importiert, das die Textverarbeitung von Word-Dokumenten ermöglicht. Beim Öffnen des Dokuments wird der gesamte Text in einen einzigen Textblock zusammengeführt. Die Umwandlung des Texts in einen einzigen Textblock erleichtert die spätere Analyse und Zählung der Wortfrequenzen, da der Text in einer strukturierten Form vorliegt. Dieser zusammengeführte Text wird anschliessend in Wörter aufgeteilt, und Satzzeichen werden entfernt. Danach werden die Häufigkeiten der Wörter gezählt, und das Ergebnis wird als Wörterbuch zurückgegeben. Falls die Datei nicht gefunden wird, erfolgt eine entsprechende Fehlermeldung. \n",
    "\n",
    "Quelle für das Einlesen und Bearbeiten von docx Dateien: https://www.youtube.com/watch?v=26vNgM_wSAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef42b81-e0b6-4f97-a979-66099f14e16d",
   "metadata": {},
   "source": [
    "### Erstellung von Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebe42cb-8252-4c4f-93f7-2d9cff5fe7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dateiname: Übersicht Programmierung Python.docx\n",
      "Autor: Cristian Ruiz\n",
      "\n",
      "Dateiname: Kapitel 1.docx\n",
      "Autor: Cristian Ruiz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verzeichnis, in dem die Dokumente gespeichert sind\n",
    "verzeichnis = '/Users/cristianruiz/Desktop/CAS/Python/Semesterarbeit 2/Dokumente/'\n",
    "\n",
    "# Liste, um die Dokumente im Korpus zu speichern\n",
    "korpus = []\n",
    "\n",
    "# Durchsuchen des Verzeichnisses nach .docx-Dateien\n",
    "for dateiname in os.listdir(verzeichnis):\n",
    "    if dateiname.endswith('.docx'):\n",
    "        dateipfad = os.path.join(verzeichnis, dateiname)\n",
    "        \n",
    "        # Öffnen des .docx-Dokuments\n",
    "        doc = docx.Document(dateipfad)\n",
    "        \n",
    "        # Extrahieren des Autors \n",
    "        autor = doc.core_properties.author\n",
    "        \n",
    "        # Erstellen eines Dictionary für jedes Dokument und Hinzufügen zum Korpus\n",
    "        dokument = {\n",
    "            'dateiname': dateiname,\n",
    "            'autor': autor\n",
    "        }\n",
    "        korpus.append(dokument)\n",
    "\n",
    "# Beispiel für den Zugriff auf Dokumente im Korpus\n",
    "for dokument in korpus:\n",
    "    print(f\"Dateiname: {dokument['dateiname']}\")\n",
    "    print(f\"Autor: {dokument['autor']}\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec1425-a074-4d4f-82f6-600ff1b002d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Erklärung zum Code:**\n",
    "\n",
    "Der Code sucht nach `.docx`-Dateien in einem angegebenen Verzeichnis. Dazu wird die Python-Bibliothek `os` importiert, die Dateiverzeichnisse durchsuchen und Dateinamen verwalten kann. Mit `os.listdir()` wird eine Liste von Dateinamen im Verzeichnis erstellt, und die Endung `.docx` wird überprüft, um sicherzustellen, dass es sich um Word-Dokumente handelt. Der Autor wird aus den Word-Dokumenten extrahiert und zusammen mit dem Dateinamen in einem Dictionary für jedes Dokument im Korpus gespeichert. Schliesslich wird der Autor für jedes Dokument im Korpus ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f253f0-d61b-4bd2-915b-55636eec3b71",
   "metadata": {},
   "source": [
    "### Funktion idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7414773e-5640-4ff5-9e15-0c57f6f4b293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF-Wert für das Wort 'Durchschnitt': 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import math\n",
    "\n",
    "# Verzeichnis, in dem die Dokumente gespeichert sind\n",
    "verzeichnis = '/Users/cristianruiz/Desktop/CAS/Python/Semesterarbeit 2/Dokumente/'\n",
    "\n",
    "# Liste, um die Dokumente im Korpus zu speichern\n",
    "korpus = []\n",
    "\n",
    "# Durchsuchen des Verzeichnisses nach .docx-Dateien\n",
    "for dateiname in os.listdir(verzeichnis):\n",
    "    if dateiname.endswith('.docx'):\n",
    "        dateipfad = os.path.join(verzeichnis, dateiname)\n",
    "        \n",
    "        # Öffnen des .docx-Dokuments\n",
    "        doc = docx.Document(dateipfad)\n",
    "        \n",
    "        # Text aus dem Dokument extrahieren und in einen einzigen Textblock zusammenführen\n",
    "        text = ' '.join(paragraph.text for paragraph in doc.paragraphs)\n",
    "        \n",
    "        # Hinzufügen des Texts zum Korpus\n",
    "        korpus.append(text)\n",
    "\n",
    "# Funktion zur Berechnung der IDF für ein gegebenes Wort im Korpus\n",
    "def idf(Wort, Korpus):\n",
    "    N = len(Korpus)  # Anzahl der Dokumente im Korpus\n",
    "    n = sum(1 for Dokument in Korpus if Wort in Dokument)  # Anzahl der Dokumente, in denen das Wort vorkommt\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    idf_wert = math.log(N / n)\n",
    "    return idf_wert\n",
    "\n",
    "# Beispiel anahnd des Wortes \"Durchschnitt\"\n",
    "wort = \"Durchschnitt\"\n",
    "\n",
    "# Berechnen der IDF für das gesuchte Wort\n",
    "idf_wert = idf(wort, korpus)\n",
    "\n",
    "# Ausgabe des IDF-Werts\n",
    "print(f\"IDF-Wert für das Wort '{wort}': {idf_wert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac3992-05d5-47fe-b758-f677e8dd40da",
   "metadata": {},
   "source": [
    "**Erklärung zum Code**\n",
    "\n",
    "Der Code berechnet die Inverse Dokumentfrequenz (IDF) für ein bestimmtes Wort, in diesem Fall \"Durchschnitt\" in dem Korpus von Dukumenten welches ebenfalls angelegt wird. Hierzu wird eine Funktion namens \"idf\" definiert. Diese Funktion ermittelt zuerst die Gesamtanzahl der Dokumente im Korpus und zählt dann, wie oft das gesuchte Wort in den Dokumenten vorkommt, wobei Mehrfachvorkommen innerhalb eines einzelnen Dokuments berücksichtigt werden. Um eine Division durch Null zu vermeiden, wird überprüft, ob das Wort in keinem der Dokumente erscheint. Falls das der Fall ist, wird ein IDF-Wert von 0 zurückgegeben. Andernfalls erfolgt die Berechnung des IDF-Werts, indem der Logarithmus von N (der Gesamtanzahl der Dokumente) geteilt durch n (der Anzahl der Dokumente, in denen das Wort vorkommt) angewandt wird. Schliesslich wird der berechnete IDF-Wert für das angegebene Wort ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becca77f-2231-4c30-8021-e81f4a98993c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF-Wert für das Wort 'Durchschnitt' im Dokument 1: 5.545177444479562\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import math\n",
    "\n",
    "# Verzeichnis, in dem die Dokumente gespeichert sind\n",
    "verzeichnis = '/Users/cristianruiz/Desktop/CAS/Python/Semesterarbeit 2/Dokumente/'\n",
    "\n",
    "# Liste, um die Dokumente im Korpus zu speichern\n",
    "korpus = []\n",
    "\n",
    "# Durchsuchen des Verzeichnisses nach .docx-Dateien\n",
    "for dateiname in os.listdir(verzeichnis):\n",
    "    if dateiname.endswith('.docx'):\n",
    "        dateipfad = os.path.join(verzeichnis, dateiname)\n",
    "        \n",
    "        # Öffnen des .docx-Dokuments\n",
    "        doc = docx.Document(dateipfad)\n",
    "        \n",
    "        # Text aus dem Dokument extrahieren und in einen einzigen Textblock zusammenführen\n",
    "        text = ' '.join(paragraph.text for paragraph in doc.paragraphs)\n",
    "        \n",
    "        # Hinzufügen des Texts zum Korpus\n",
    "        korpus.append(text)\n",
    "\n",
    "# Funktion zur Berechnung der IDF für ein gegebenes Wort im Korpus\n",
    "def idf(Wort, Korpus):\n",
    "    N = len(Korpus)  # Anzahl der Dokumente im Korpus\n",
    "    n = sum(1 for Dokument in Korpus if Wort in Dokument)  # Anzahl der Dokumente, in denen das Wort vorkommt\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    idf_wert = math.log(N / n)\n",
    "    return idf_wert\n",
    "\n",
    "# Funktion zur Berechnung des TF-IDF-Werts für ein Wort in einem Dokument\n",
    "def tf_idf(Wort, Dokument, Korpus):\n",
    "    # Berechnung der TF für das gesuchte Wort im Dokument\n",
    "    tf = Dokument.count(Wort)\n",
    "\n",
    "    # Berechnung des IDF-Werts mit vorhandenen 'idf' Funktion\n",
    "    idf_wert = idf(Wort, Korpus)\n",
    "\n",
    "    # Berechnung des TF-IDF-Werts\n",
    "    tf_idf_wert = tf * idf_wert\n",
    "\n",
    "    return tf_idf_wert\n",
    "\n",
    "# Beispiel anhand des Wortes \"Durchschnitt\"\n",
    "gesuchtes_wort = \"Durchschnitt\"\n",
    "\n",
    "# Wählen Sie ein Dokument aus dem Korpus (z.B. das erste Dokument)\n",
    "dokument_index = 1\n",
    "ausgewaehltes_dokument = korpus[dokument_index]\n",
    "\n",
    "# Berechnen des TF-IDF-Werts für das gesuchte Wort im ausgewählten Dokument\n",
    "tf_idf_wert = tf_idf(gesuchtes_wort, ausgewaehltes_dokument, korpus)\n",
    "\n",
    "# Ausgabe des TF-IDF-Werts\n",
    "print(f\"TF-IDF-Wert für das Wort '{gesuchtes_wort}' im Dokument {dokument_index}: {tf_idf_wert}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e2c41-d985-4671-81c0-051a91678db6",
   "metadata": {},
   "source": [
    "**Erklärung zum Code**\n",
    "\n",
    "Dieser Code enthält nun alle vorherigen Schritte (Erstellung von Korpus mit Dokumenten, Anzahl Wörter von Dokumenten zählen, Berechnung von IDF-Wert, etc.). Neu wird der TF-IDF-Wert berechnet, dies auch wieder mit dem Beispielwort \"Durchschnitt\" und für das 1. Dokument im Korpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
